{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7395 entries, 0 to 7394\n",
      "Data columns (total 29 columns):\n",
      "url                               7395 non-null object\n",
      "urlid                             7395 non-null int64\n",
      "boilerplate                       7395 non-null object\n",
      "alchemy_category                  7395 non-null object\n",
      "alchemy_category_score            7395 non-null object\n",
      "avglinksize                       7395 non-null float64\n",
      "commonlinkratio_1                 7395 non-null float64\n",
      "commonlinkratio_2                 7395 non-null float64\n",
      "commonlinkratio_3                 7395 non-null float64\n",
      "commonlinkratio_4                 7395 non-null float64\n",
      "compression_ratio                 7395 non-null float64\n",
      "embed_ratio                       7395 non-null float64\n",
      "framebased                        7395 non-null int64\n",
      "frameTagRatio                     7395 non-null float64\n",
      "hasDomainLink                     7395 non-null int64\n",
      "html_ratio                        7395 non-null float64\n",
      "image_ratio                       7395 non-null float64\n",
      "is_news                           7395 non-null object\n",
      "lengthyLinkDomain                 7395 non-null int64\n",
      "linkwordscore                     7395 non-null int64\n",
      "news_front_page                   7395 non-null object\n",
      "non_markup_alphanum_characters    7395 non-null int64\n",
      "numberOfLinks                     7395 non-null int64\n",
      "numwords_in_url                   7395 non-null int64\n",
      "parametrizedLinkRatio             7395 non-null float64\n",
      "spelling_errors_ratio             7395 non-null float64\n",
      "label                             7395 non-null int64\n",
      "title                             7383 non-null object\n",
      "body                              7338 non-null object\n",
      "dtypes: float64(12), int64(9), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"data/stumbleupon.tsv\", sep='\\t')\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "title=data['title']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       IBM Sees Holographic Calls Air Breathing Batte...\n",
       "1       The Fully Electronic Futuristic Starting Gun T...\n",
       "2       Fruits that Fight the Flu fruits that fight th...\n",
       "3                     10 Foolproof Tips for Better Sleep \n",
       "4       The 50 Coolest Jerseys You Didn t Know Existed...\n",
       "5                               Genital Herpes Treatment \n",
       "6                       fashion lane American Wild Child \n",
       "7       Racing For Recovery by Dean Johnson racing for...\n",
       "8                      Valet The Handbook 31 Days 31 days\n",
       "9             Cookies and Cream Brownies How Sweet It Is \n",
       "10      Business Financial News Breaking US Internatio...\n",
       "11      A Tip of the Cap to The Greatest Iron Man of T...\n",
       "12                         9 Foods That Trash Your Teeth \n",
       "13                                                       \n",
       "14      French Onion Steaks with Red Wine Sauce french...\n",
       "15      Izabel Goulart Swimsuit by Kikidoll 2012 Sport...\n",
       "16                    Liquid Mountaineering The Awesomer \n",
       "17                                                   None\n",
       "18                          Grilled Peaches Sugarcrafter \n",
       "19      How to Make Your Home Healthier A Room by Room...\n",
       "20      Olympic Soccer Babe Alex Morgan Medal Winning ...\n",
       "21         BBC Food Recipes Blueberry and lemon traybake \n",
       "22      Quit Smoking Counter Online counter that measu...\n",
       "23            Original techniques to tie your shoe laces \n",
       "24                                                       \n",
       "25       Best College Football Fan Sign Ever Alabama Fan \n",
       "26                                    Breaking News Blog \n",
       "27                     The Alton Brown Flower Pot Smoker \n",
       "28          Supermodels show off their bikini bods Humor \n",
       "29      Genevieve Morton Swimsuit by Tyler Rose Swimwe...\n",
       "                              ...                        \n",
       "7365    Chocolate Chip S mores Cookies of the Day choc...\n",
       "7366    Money Happiness Newsweek money & happiness - n...\n",
       "7367                                                     \n",
       "7368    Sourdough Sour Cherry Bread Pudding with Cherr...\n",
       "7369    Noble Pig Mini Peanut Butter Finger Cheesecake...\n",
       "7370            Fancy Knot Dress in Clothes at Nasty Gal \n",
       "7371                        Perfect Pumpkin Bread Recipe \n",
       "7372    Get the Lead Out Cartridge Free Erasable Penci...\n",
       "7373    blog khymos org dedicated to molecular gastron...\n",
       "7374    Versace launches haute couture for autumn wint...\n",
       "7375                                 What Megan s Making \n",
       "7376        Chinese Food Recipes Cooking Chinese Cuisine \n",
       "7377    Google Gives iPhone Users Browser Choice For P...\n",
       "7378       12 Smoothies Recipes and Cooking Food Network \n",
       "7379    Toasted Sesame Ginger Salmon TechMunch Boston ...\n",
       "7380          iVillage s 25 Most Popular Recipes of 2010 \n",
       "7381                                       Caravan Style \n",
       "7382    Mountain Dew Cupcakes All Things Cupcake mount...\n",
       "7383                                  80s kids Random RR \n",
       "7384                        Homemade Cake Mix i am baker \n",
       "7385                           MARKET HQ Brands MINKPINK \n",
       "7386    How to Make No Knead Pizza Dough No Knead Pizz...\n",
       "7387                       Vintage Funk A Chic Direction \n",
       "7388    New York Best Place to Watch Wildlife Jamaica ...\n",
       "7389                      Gummy Snake Worth1000 Contests \n",
       "7390    Kno Raises 46 Million More To Build Most Power...\n",
       "7391                                  Why I Miss College \n",
       "7392    Sweet Potatoes Eat This Not That  i'm eating t...\n",
       "7393                                      Naturally Ella \n",
       "7394    Esti Ginzburg Swimsuit by Letarte by Lisa Cabr...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b5a602cd549e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \"\"\"\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english', binary=True)\n",
    "vectorizer.fit(title)\n",
    "X=vectorizer.transform(title)\n",
    "y = data['label']\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model,X,y)\n",
    "scores\n",
    "print('CV scores:{}'.format(scores))\n",
    "\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "#estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "#score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "#print(\"Score with the entire dataset = %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
